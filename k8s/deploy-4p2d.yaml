# SPDX-FileCopyrightText: Copyright (c) 2025-2026 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
# SPDX-License-Identifier: Apache-2.0
#
# GLM-4.7-NVFP4 Disaggregated Deployment
# 4 Prefill + 2 Decode workers (6 nodes, 24 GPUs total)
# Prefill: 4 nodes with TP=16, DP=4 (4 GPUs per node)
# Decode: 2 nodes with TP=8, DP=2 (4 GPUs per node)

apiVersion: nvidia.com/v1alpha1
kind: DynamoGraphDeployment
metadata:
  name: glm47-nvfp4-4p2d
spec:
  envs:
    - name: HF_HOME
      value: /opt/model
    - name: SGLANG_DISABLE_TP_MEMORY_INBALANCE_CHECK
      value: "1"
    - name: SGLANG_DISAGGREGATION_HEARTBEAT_MAX_FAILURE
      value: "100000"
    - name: SGLANG_DISAGGREGATION_BOOTSTRAP_TIMEOUT
      value: "100000"
    - name: SGLANG_DISAGGREGATION_WAITING_TIMEOUT
      value: "100000"
    - name: TORCH_DISTRIBUTED_DEFAULT_TIMEOUT
      value: "1800"
    - name: NCCL_TIMEOUT
      value: "3600"
    - name: NCCL_BLOCKING_WAIT
      value: "1"
    - name: NCCL_ASYNC_ERROR_HANDLING
      value: "1"
    - name: MC_FORCE_MNNVL
      value: "1"
    - name: NCCL_MNNVL_ENABLE
      value: "1"
    - name: NCCL_CUMEM_ENABLE
      value: "1"
    - name: FLASHINFER_WORKSPACE_BASE
      value: /fsw-home
    - name: TORCH_EXTENSIONS_DIR
      value: /fsw-home/.cache/torch_extensions
    - name: TRITON_CACHE_DIR
      value: /fsw-home/.triton/cache
  pvcs:
    - name: model-cache
      create: false
  services:
    Frontend:
      componentType: frontend
      replicas: 1
      volumeMounts:
        - name: model-cache
          mountPoint: /opt/model
      extraPodSpec:
        mainContainer:
          image: nvcr.io/nvidia/ai-dynamo/sglang-runtime:0.8.1
    decode:
      componentType: worker
      subComponentType: decode
      replicas: 1
      multinode:
        nodeCount: 2
      resources:
        limits:
          gpu: "4"
      volumeMounts:
        - name: model-cache
          mountPoint: /opt/model
      sharedMemory:
        size: 40Gi
      extraPodSpec:
        mainContainer:
          image: nvcr.io/nvidia/ai-dynamo/sglang-runtime:0.8.1
          workingDir: /sgl-workspace/dynamo
          command:
            - python3
            - -m
            - dynamo.sglang
          args:
            - --model-path
            - /opt/model/GLM-4.7-NVFP4
            - --served-model-name
            - glm-4.7
            - --trust-remote-code
            - --quantization
            - modelopt_fp4
            - --kv-cache-dtype
            - fp8_e4m3
            - --attention-backend
            - flashinfer
            - --disaggregation-mode
            - decode
            - --disaggregation-transfer-backend
            - nixl
            - --disaggregation-bootstrap-port
            - "30001"
            - --tensor-parallel-size
            - "8"
            - --data-parallel-size
            - "2"
            - --enable-dp-attention
            - --moe-dense-tp-size
            - "1"
            - --mem-fraction-static
            - "0.85"
            - --stream-interval
            - "10"
            - --watchdog-timeout
            - "600"
            - --host
            - 0.0.0.0
    prefill:
      componentType: worker
      subComponentType: prefill
      replicas: 1
      multinode:
        nodeCount: 4
      resources:
        limits:
          gpu: "4"
      volumeMounts:
        - name: model-cache
          mountPoint: /opt/model
      sharedMemory:
        size: 40Gi
      extraPodSpec:
        mainContainer:
          image: nvcr.io/nvidia/ai-dynamo/sglang-runtime:0.8.1
          workingDir: /sgl-workspace/dynamo
          command:
            - python3
            - -m
            - dynamo.sglang
          args:
            - --model-path
            - /opt/model/GLM-4.7-NVFP4
            - --served-model-name
            - glm-4.7
            - --trust-remote-code
            - --quantization
            - modelopt_fp4
            - --kv-cache-dtype
            - fp8_e4m3
            - --attention-backend
            - flashinfer
            - --disaggregation-mode
            - prefill
            - --disaggregation-transfer-backend
            - nixl
            - --disaggregation-bootstrap-port
            - "30001"
            - --tensor-parallel-size
            - "16"
            - --data-parallel-size
            - "4"
            - --enable-dp-attention
            - --moe-dense-tp-size
            - "1"
            - --mem-fraction-static
            - "0.85"
            - --stream-interval
            - "10"
            - --watchdog-timeout
            - "600"
            - --load-balance-method
            - round_robin
            - --host
            - 0.0.0.0
